{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdDJ1YRe7+VkfxVQ/QitqF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Cats-vs.-Dogs Image Classification. Preprocessing\n","This `utils` notebook contains the data preprocessing and transformation of the cats and dogs images dataset. In particular, the first 2,000 images of the dataset are resized to 150x150 pixels and saved to a single CSV file.\n","\n","This notebook is designed to be executed in a Google Collab environment.\n","\n","- **Dataset Reference**: Sachin, Shaunthesheep (2020). Dataset: Cats-vs-Dogs : image dataset for binary classification. URL: [https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset](https://www.kaggle.com/shaunthesheep/microsoft-catsvsdogs-dataset)"],"metadata":{"id":"wI22ZAVnPQpT"}},{"cell_type":"markdown","source":["## Package dependencies, Drive mount and parameters definition"],"metadata":{"id":"3cbchKLIQA2Y"}},{"cell_type":"code","source":["import kagglehub\n","import os\n","import shutil\n","import cv2\n","import pandas as pd\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from google.colab import files\n","from google.colab import drive\n","import stat\n","import sys\n","import io\n","import zipfile\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Define parameters for dataset processing\n","DATASET = \"shaunthesheep/microsoft-catsvsdogs-dataset\"  # Dataset identifier\n","MAX_IMAGES_PER_CLASS = 1000  # Limit to 1000 images per class (cats and dogs)\n","OUTPUT_DIR = f\"/content/drive/MyDrive/Portfolio/data/cats_dogs{MAX_IMAGES_PER_CLASS}\"  # Output directory for processed images\n","ZIP_OUTPUT_1 = \"/content/drive/MyDrive/Portfolio/data/CatsDogsDataset_1.zip\"  # First ZIP file for CSV output\n","ZIP_OUTPUT_2 = \"/content/drive/MyDrive/Portfolio/data/CatsDogsDataset_2.zip\"  # Second ZIP file for CSV output\n","CSV_FILENAME = \"CatsDogsDataset.csv\"  # Base name for CSV files\n","# Problematic files to skip (e.g. corrupted files)\n","SKIP_FILES = [\"7981.jpg\", \"10125.jpg\", \"10404.jpg\", \"10501.jpg\", \"10820.jpg\",\n","              \"10158.jpg\", \"10401.jpg\", \"10747.jpg\", \"10797.jpg\"]"],"metadata":{"id":"YDyb8NSDP_9q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Function definition"],"metadata":{"id":"b7M5ISb6VD34"}},{"cell_type":"code","source":["def is_valid_image_cv2(file_path):\n","    \"\"\"Check if a file is a valid image using cv2.imread.\"\"\"\n","    try:\n","        img = cv2.imread(file_path)\n","        if img is None or img.size == 0:\n","            return False\n","        return True\n","    except Exception:\n","        return False\n","\n","def copy_images(source_dir, dest_dir, max_images, class_name):\n","    \"\"\"Copy valid images from source to destination, skipping problematic files.\"\"\"\n","    os.makedirs(dest_dir, exist_ok=True)  # Create destination directory if it doesn't exist\n","    count = 0  # Track number of copied images\n","    for filename in sorted(os.listdir(source_dir)):\n","        if count >= max_images:  # Stop if max image limit is reached\n","            break\n","        if filename in SKIP_FILES:  # Skip specified problematic files\n","            continue\n","        src_path = os.path.join(source_dir, filename)\n","        dest_path = os.path.join(dest_dir, f\"{class_name}_{count:03d}.jpg\")\n","        if os.path.isfile(src_path) and is_valid_image_cv2(src_path):\n","            try:\n","                img = cv2.imread(src_path)  # Read image with OpenCV\n","                if img is not None:\n","                    cv2.imwrite(dest_path, img)  # Save image to destination\n","                    count += 1\n","            except Exception:\n","                pass\n","    return count  # Return number of images copied\n","\n","def create_data_generator(train_dir):\n","    \"\"\"Create a data generator for image processing.\"\"\"\n","    train_datagen = ImageDataGenerator()  # Initialize data generator\n","    train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(150, 150),  # Resize images to 150x150\n","        batch_size=20,  # Process 20 images per batch\n","        class_mode='binary',  # Binary classification (cats vs dogs)\n","        shuffle=False  # Maintain order for consistent file paths and labels\n","    )\n","    return train_generator\n","\n","def generate_column_names():\n","    \"\"\"Generate column names for pixel values (R_i_j, G_i_j, B_i_j) for 150x150x3 images.\"\"\"\n","    columns = []\n","    for i in range(1, 151):  # Rows 1 to 150\n","        for j in range(1, 151):  # Columns 1 to 150\n","            columns.append(f\"R_{i}_{j}\")  # Red channel\n","            columns.append(f\"G_{i}_{j}\")  # Green channel\n","            columns.append(f\"B_{i}_{j}\")  # Blue channel\n","    return columns\n","\n","def extract_pixels_and_save_in_batches(generator, output_zip1, output_zip2, csv_filename1, csv_filename2):\n","    \"\"\"Extract pixel values in batches and save as two CSVs in separate ZIP files.\"\"\"\n","    pixel_columns = generate_column_names()  # Generate pixel column names\n","    columns = pixel_columns + ['Class']  # Add class column\n","    total_images = len(generator.filenames)  # Total number of images\n","    batch_size = 200  # Process 200 images per batch\n","    split_point = total_images // 2  # Split data into two parts\n","\n","    # Initialize buffers for two CSVs\n","    csv_buffer1 = io.StringIO()\n","    csv_buffer2 = io.StringIO()\n","    pd.DataFrame(columns=columns).to_csv(csv_buffer1, index=False)  # Write headers to first CSV\n","    pd.DataFrame(columns=columns).to_csv(csv_buffer2, index=False)  # Write headers to second CSV\n","\n","    pixel_data = []  # Store pixel values\n","    labels = []  # Store class labels\n","    image_count = 0  # Track total processed images\n","\n","    for i in range(len(generator)):\n","        images, batch_labels = next(generator)  # Get next batch of images and labels\n","        for j in range(images.shape[0]):\n","            pixel_values = images[j].flatten().astype(np.uint8)  # Flatten image to 1D array\n","            pixel_data.append(pixel_values)\n","            labels.append(int(batch_labels[j]))  # Store class label\n","            image_count += 1\n","\n","            # Process batch when batch_size is reached\n","            if len(pixel_data) >= batch_size:\n","                data = np.hstack((np.array(pixel_data), np.array(labels).reshape(-1, 1)))\n","                df = pd.DataFrame(data, columns=columns)\n","                # Write to appropriate CSV buffer based on image count\n","                if image_count <= split_point:\n","                    df.to_csv(csv_buffer1, mode='a', header=False, index=False)\n","                else:\n","                    df.to_csv(csv_buffer2, mode='a', header=False, index=False)\n","                pixel_data, labels = [], []  # Clear memory\n","\n","    # Save any remaining data\n","    if pixel_data:\n","        data = np.hstack((np.array(pixel_data), np.array(labels).reshape(-1, 1)))\n","        df = pd.DataFrame(data, columns=columns)\n","        if image_count <= split_point:\n","            df.to_csv(csv_buffer1, mode='a', header=False, index=False)\n","        else:\n","            df.to_csv(csv_buffer2, mode='a', header=False, index=False)\n","\n","    # Write CSV buffers to two ZIP files\n","    with zipfile.ZipFile(output_zip1, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n","        zf.writestr(csv_filename1, csv_buffer1.getvalue())\n","    with zipfile.ZipFile(output_zip2, 'w', compression=zipfile.ZIP_DEFLATED) as zf:\n","        zf.writestr(csv_filename2, csv_buffer2.getvalue())\n","\n","def delete_all_images(dataset_path, output_dir):\n","    \"\"\"Delete all downloaded and copied images, handling read-only files.\"\"\"\n","    def remove_readonly(func, path, _):\n","        \"\"\"Clear read-only flag and retry deletion.\"\"\"\n","        os.chmod(path, stat.S_IWRITE)\n","        func(path)\n","\n","    try:\n","        # Delete the copied images\n","        if os.path.exists(output_dir):\n","            shutil.rmtree(output_dir, onerror=remove_readonly)\n","        # Original dataset deletion is commented out as it's environment-specific\n","        # if os.path.exists(dataset_path):\n","        #     shutil.rmtree(dataset_path, onerror=remove_readonly)\n","    except Exception:\n","        pass"],"metadata":{"id":"Cbg3j0i5VDAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Execution: Main"],"metadata":{"id":"F9Y68yxhVHUT"}},{"cell_type":"code","source":["print(\"Downloading dataset...\")\n","try:\n","    path = kagglehub.dataset_download(DATASET)\n","    print(f\"Dataset downloaded to: {path}\")\n","except Exception as e:\n","    print(f\"Failed to download dataset: {e}\")\n","    raise\n","\n","# Define paths\n","cat_dir = os.path.join(path, \"PetImages\", \"Cat\")\n","dog_dir = os.path.join(path, \"PetImages\", \"Dog\")\n","output_cat_dir = os.path.join(OUTPUT_DIR, \"Cat\")\n","output_dog_dir = os.path.join(OUTPUT_DIR, \"Dog\")\n","\n","# Check if folders exist\n","if not os.path.exists(cat_dir) or not os.path.exists(dog_dir):\n","    print(\"PetImages/Cat or PetImages/Dog folders not found\")\n","    raise FileNotFoundError(\"Required dataset folders missing\")\n","\n","# Copy images\n","print(\"Copying cat images...\")\n","cat_count = copy_images(cat_dir, output_cat_dir, MAX_IMAGES_PER_CLASS, \"cat\")\n","print(\"Copying dog images...\")\n","dog_count = copy_images(dog_dir, output_dog_dir, MAX_IMAGES_PER_CLASS, \"dog\")\n","print(f\"Copied {cat_count} cat images and {dog_count} dog images\")\n","\n","# Verify output directories\n","if cat_count == 0 or dog_count == 0:\n","    print(\"No images copied for one or both classes\")\n","    raise ValueError(\"Image copying failed\")\n","\n","# Create data generator\n","print(\"Creating data generator...\")\n","train_generator = create_data_generator(OUTPUT_DIR)\n","if train_generator.samples == 0:\n","    print(\"No images found by data generator\")\n","    raise ValueError(\"Data generator is empty\")\n","\n","# Extract and save in batches\n","print(\"Extracting and saving pixel values in batches...\")\n","extract_pixels_and_save_in_batches(train_generator, ZIP_OUTPUT_1, ZIP_OUTPUT_2, CSV_FILENAME, CSV_FILENAME)\n","\n","# Delete images\n","print(\"Deleting images...\")\n","delete_all_images(path, OUTPUT_DIR)"],"metadata":{"id":"9tcPGpkze57z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/drive/MyDrive/Portfolio/data/"],"metadata":{"id":"4bZA6ddVgcWU"},"execution_count":null,"outputs":[]}]}